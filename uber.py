# -*- coding: utf-8 -*-
"""uber.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ha7M05BnrYa2pdaJ-q_ho2pIFwcrGLwO
"""

from google.colab import files
files.upload()   # Upload kaggle.json when prompted

# 2ï¸âƒ£ Create directory and move kaggle.json
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# 3ï¸âƒ£ Confirm file is in place
!ls ~/.kaggle

# 4ï¸âƒ£ Download dataset
!kaggle datasets download -d yasserh/uber-fares-dataset

# 5ï¸âƒ£ Unzip
!unzip uber-fares-dataset.zip

import pandas as pd
df = pd.read_csv("uber.csv")  # Replace with correct filename after unzip
df.head()

# âœ… Step 1: Download dataset using Kaggle CLI (if not already done)
!kaggle datasets download -d yasserh/uber-fares-dataset
!unzip -o uber-fares-dataset.zip

# âœ… Step 2: Data Processing and Model Training

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

# âœ… Load dataset directly
df = pd.read_csv("uber.csv")  # Change if file name is different

print("\nâœ… Dataset Loaded Successfully!")
print("\nDataset Columns:", df.columns.tolist())
print(df.head())

# âœ… Data Preprocessing
target_column = 'fare_amount'

df.dropna(inplace=True)

if 'pickup_datetime' in df.columns:
    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], errors='coerce')
    df.dropna(subset=['pickup_datetime'], inplace=True)
    df['hour'] = df['pickup_datetime'].dt.hour
    df['day_of_week'] = df['pickup_datetime'].dt.dayofweek
    df['month'] = df['pickup_datetime'].dt.month
    df.drop(['pickup_datetime'], axis=1, inplace=True)

df.drop([col for col in ['key', 'id'] if col in df.columns], axis=1, inplace=True)

# âœ… Outlier Handling
plt.figure(figsize=(10, 5))
sns.boxplot(x=df[target_column])
plt.title("Fare Amount Outlier Detection")
plt.show()

df = df[(df[target_column] > 1) & (df[target_column] < 100)]

# âœ… Correlation Check
plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

# âœ… Model Preparation
X = df.drop([target_column], axis=1)
y = df[target_column]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# âœ… Model Training
models = {
    "Linear Regression": LinearRegression(),
    "Random Forest": RandomForestRegressor(random_state=42, n_estimators=100)
}

results = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    results[name] = {"R2 Score": r2, "RMSE": rmse}
    print(f"\n--- {name} ---")
    print(f"R2 Score : {r2:.4f}")
    print(f"RMSE     : {rmse:.4f}")

# âœ… Feature Importance (Random Forest)
rf_model = models["Random Forest"]
if hasattr(rf_model, 'feature_importances_'):
    feature_importances = rf_model.feature_importances_
    feature_names = df.drop([target_column], axis=1).columns
    plt.figure(figsize=(10, 6))
    sns.barplot(x=feature_importances, y=feature_names)
    plt.title("Random Forest Feature Importance")
    plt.xlabel("Importance")
    plt.ylabel("Feature")
    plt.show()

# âœ… Summary
print("\nðŸ“Š Model Comparison Summary:")
summary_df = pd.DataFrame(results).T
print(summary_df)