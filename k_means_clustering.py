# -*- coding: utf-8 -*-
"""K-Means Clustering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ls5rQ8BGEHUY9FFBDMF_qqQFnRSkjfgN
"""

# ---------------------------------------------------------
# 1. Import required libraries
# ---------------------------------------------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from scipy.cluster.hierarchy import dendrogram, linkage

# ---------------------------------------------------------
# 2. Load dataset
# ---------------------------------------------------------
df = pd.read_csv("sales_data_sample.csv", encoding='latin1')

print("Dataset loaded successfully!")
df.head()

# ---------------------------------------------------------
# 3. Select numeric features only
# ---------------------------------------------------------
df_numeric = df.select_dtypes(include=[np.number])

print("Numeric Columns Used for Clustering:\n", df_numeric.columns)
df_numeric.head()

# ---------------------------------------------------------
# 4. Handle missing values (if any)
# ---------------------------------------------------------
df_numeric = df_numeric.fillna(df_numeric.mean())

# ---------------------------------------------------------
# 5. Normalize the data
# ---------------------------------------------------------
scaler = StandardScaler()
scaled_data = scaler.fit_transform(df_numeric)

print("Data normalized successfully!")

# ---------------------------------------------------------
# 6. Elbow Method to find optimal K
# ---------------------------------------------------------

inertia = []
K_range = range(1, 11)

for k in K_range:
    km = KMeans(n_clusters=k, random_state=42)
    km.fit(scaled_data)
    inertia.append(km.inertia_)

plt.figure(figsize=(8, 5))
plt.plot(K_range, inertia, marker='o')
plt.title("Elbow Method for Optimal K")
plt.xlabel("Number of Clusters (K)")
plt.ylabel("Inertia")
plt.grid(True)
plt.show()

# ---------------------------------------------------------
# 7. Train K-Means with optimal K (example: K=4)
# ---------------------------------------------------------

optimal_k = 4   # <-- choose based on elbow plot

kmeans = KMeans(n_clusters=optimal_k, random_state=42)
clusters = kmeans.fit_predict(scaled_data)

df["KMeans_Cluster"] = clusters

df.head()

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
pca_data = pca.fit_transform(scaled_data)

plt.figure(figsize=(8, 6))
plt.scatter(pca_data[:, 0], pca_data[:, 1], c=clusters, cmap='rainbow')
plt.title("K-Means Clustering Visualization")
plt.xlabel("PCA 1")
plt.ylabel("PCA 2")
plt.show()

# ---------------------------------------------------------
# 8. Hierarchical Clustering (Dendrogram)
# ---------------------------------------------------------

plt.figure(figsize=(12, 6))
linked = linkage(scaled_data, method='ward')

dendrogram(linked)
plt.title('Hierarchical Clustering Dendrogram')
plt.xlabel('Samples')
plt.ylabel('Distance')
plt.show()

from sklearn.cluster import AgglomerativeClustering

hc = AgglomerativeClustering(n_clusters=4)  # choose based on dendrogram
hc_clusters = hc.fit_predict(scaled_data)

df['HC_Cluster'] = hc_clusters

df.head()